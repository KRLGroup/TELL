{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26112f98-4e8d-4056-ab62-58e78faa4c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spideralessio/.conda/envs/len/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc55b85-9e3e-44d2-ab19-6a69e8b9b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tell import LogicalLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7c0a54f-9645-479f-aee0-bb480ca7b40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff035a6f4d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86315236-1346-4db4-9669-c14a48263fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand([1000, 10]).float()\n",
    "x = torch.hstack([x,1-x])\n",
    "y = ((x[:, 1] < 0.3)&(x[:, 2] > 0.5))|((x[:, 2] > 0.5)&(x[:, 3] > 0.7))\n",
    "y = y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7935918e-4026-447c-b240-0f89405716be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x[int(x.shape[0]*0.8):]\n",
    "x_train = x[:int(x.shape[0]*0.8)]\n",
    "y_test = y[int(x.shape[0]*0.8):]\n",
    "y_train = y[:int(x.shape[0]*0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca58b7a9-77f9-4ff1-802d-484f7d72bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x_train, y_train, x_test, y_test, epochs=3000):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "    loss_form = torch.nn.BCELoss()\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train).squeeze(-1)\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "        for layer in model.children():\n",
    "            if hasattr(layer, \"weight\"):\n",
    "                loss += 0.01*layer.weight_s.sum(-1).mean()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        for p in model.parameters():\n",
    "            if p.grad is None: continue\n",
    "            # p.grad = torch.clamp(p.grad, -1, 1)\n",
    "            p.grad = torch.where(p.grad.isnan(), torch.zeros_like(p.grad), p.grad)\n",
    "            p.grad = torch.where(p.grad.isinf(), torch.zeros_like(p.grad), p.grad)\n",
    "\n",
    "        acc = ((y_pred > 0.5).long() == y_train).float().mean()\n",
    "        test_acc = ((model(x_test).squeeze(-1) > 0.5).long() == y_test).float().mean()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch: {epoch}, loss: {loss.item():.4f}, acc: {acc.item():.4f}, test_acc: {test_acc.item():.4f}\")\n",
    "            \n",
    "    rules = model[0].extract_rules()[0]\n",
    "\n",
    "    y_rule = torch.zeros_like(y_train).bool()\n",
    "    y_test_rule = torch.zeros_like(y_test).bool()\n",
    "    for rule in rules:\n",
    "        rule = list(rule)\n",
    "        y_rule |= ((x_train[:, rule] > model[0].phi_in.t[rule]).float().prod(-1) > 0.5)\n",
    "        y_test_rule |= ((x_test[:, rule] > model[0].phi_in.t[rule]).float().prod(-1) > 0.5)\n",
    "\n",
    "\n",
    "    rule_acc = (y_rule == y_train).float().mean()\n",
    "    rule_test_acc = (y_test_rule == y_test).float().mean()\n",
    "\n",
    "    print(rules)\n",
    "\n",
    "    print(f\"rule acc: {rule_acc:.4f}, rule test acc: {rule_test_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "638da122-eebc-4cf3-be38-ea63f2db3599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.3454, acc: 0.4588, test_acc: 0.4050\n",
      "epoch: 100, loss: 0.2841, acc: 0.9087, test_acc: 0.9050\n",
      "epoch: 200, loss: 0.2049, acc: 0.9538, test_acc: 0.9500\n",
      "epoch: 300, loss: 0.1550, acc: 0.9750, test_acc: 0.9550\n",
      "epoch: 400, loss: 0.1233, acc: 0.9825, test_acc: 0.9650\n",
      "epoch: 500, loss: 0.1025, acc: 0.9862, test_acc: 0.9650\n",
      "epoch: 600, loss: 0.0884, acc: 0.9912, test_acc: 0.9700\n",
      "epoch: 700, loss: 0.0786, acc: 0.9912, test_acc: 0.9750\n",
      "epoch: 800, loss: 0.0715, acc: 0.9925, test_acc: 0.9750\n",
      "epoch: 900, loss: 0.0661, acc: 0.9925, test_acc: 0.9750\n",
      "epoch: 1000, loss: 0.0505, acc: 0.9950, test_acc: 0.9750\n",
      "epoch: 1100, loss: 0.0454, acc: 0.9937, test_acc: 0.9750\n",
      "epoch: 1200, loss: 0.0413, acc: 0.9937, test_acc: 0.9750\n",
      "epoch: 1300, loss: 0.0374, acc: 0.9937, test_acc: 0.9750\n",
      "epoch: 1400, loss: 0.0343, acc: 0.9937, test_acc: 0.9800\n",
      "epoch: 1500, loss: 0.0315, acc: 0.9937, test_acc: 0.9800\n",
      "epoch: 1600, loss: 0.0291, acc: 0.9950, test_acc: 0.9800\n",
      "epoch: 1700, loss: 0.0269, acc: 0.9950, test_acc: 0.9800\n",
      "epoch: 1800, loss: 0.0248, acc: 0.9962, test_acc: 0.9800\n",
      "epoch: 1900, loss: 0.0230, acc: 0.9962, test_acc: 0.9800\n",
      "epoch: 2000, loss: 0.0214, acc: 0.9962, test_acc: 0.9800\n",
      "epoch: 2100, loss: 0.0200, acc: 0.9962, test_acc: 0.9800\n",
      "epoch: 2200, loss: 0.0186, acc: 0.9975, test_acc: 0.9800\n",
      "epoch: 2300, loss: 0.0182, acc: 0.9975, test_acc: 0.9850\n",
      "epoch: 2400, loss: 0.0164, acc: 0.9975, test_acc: 0.9800\n",
      "epoch: 2500, loss: 0.0154, acc: 0.9975, test_acc: 0.9850\n",
      "epoch: 2600, loss: 0.0145, acc: 0.9987, test_acc: 0.9850\n",
      "epoch: 2700, loss: 0.0137, acc: 1.0000, test_acc: 0.9850\n",
      "epoch: 2800, loss: 0.0129, acc: 1.0000, test_acc: 0.9900\n",
      "epoch: 2900, loss: 0.0122, acc: 1.0000, test_acc: 0.9900\n",
      "{(2, 3), (2, 11)}\n",
      "rule acc: 0.9912, rule test acc: 0.9950\n"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    LogicalLayer(x.shape[1], 1, dummy_phi_in=False),\n",
    "]\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "\n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "x_test = x_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "train(model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "570a9f6d-4ed0-403f-b9b7-9ae8ae3aa067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_prop_logic(symbols, rules, thresholds):\n",
    "    result = []\n",
    "    for rule in rules:\n",
    "        elements = [f'{symbols[i]} > {thresholds[i]:.3}' if '~' not in symbols[i] else f'{symbols[i][1:]} < {1-thresholds[i]}'  for i in rule]\n",
    "        conjunction = \" & \".join(elements)\n",
    "        result.append('('+conjunction+')')\n",
    "\n",
    "    prop_logic = \" | \".join(result)\n",
    "    return prop_logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf8a98d0-a0a4-4ebd-be13-5dd82a43e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = [f'x{i}' for i in range(x.shape[1]//2)] + [f'~x{i}' for i in range(x.shape[1]//2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccb7c4f1-8500-4bee-b1a2-b5129c590058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(x2 > 0.482 & x3 > 0.697) | (x2 > 0.482 & x1 < 0.3039592504501343)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_to_prop_logic(symbols, model[0].extract_rules()[0], model[0].phi_in.t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-len]",
   "language": "python",
   "name": "conda-env-.conda-len-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
